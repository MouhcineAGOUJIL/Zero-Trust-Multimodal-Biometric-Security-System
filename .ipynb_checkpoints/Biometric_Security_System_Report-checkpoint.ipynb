{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Zero Trust Multimodal Biometric Security System\n",
        "## Final Project Report\n",
        "\n",
        "**Author:** [Your Name/Team]\n",
        "**Date:** December 2025\n",
        "\n",
        "---\n",
        "\n",
        "### 1. Project Overview\n",
        "This project implements a state-of-the-art **Multimodal Biometric Security System** designed for high-security environments. Unlike traditional systems that rely on a single modality (like just a password or fingerprint), this system integrates three distinct biometric traits:\n",
        "1.  **Face Recognition** (ResNet + BioHashing)\n",
        "2.  **Fingerprint Recognition** (Siamese CNN + IoM Hashing)\n",
        "3.  **Palm Verification** (Siamese CNN + IoM Hashing)\n",
        "\n",
        "Furthermore, it employs a **Zero Trust Architecture**, meaning no user is trusted by default. Every access request is evaluated based on:\n",
        "*   **Biometric Identity** (Who you are)\n",
        "*   **Contextual Data** (Time of access, IP address trust score)\n",
        "\n",
        "### 2. System Architecture\n",
        "The system is built as a modern full-stack web application:\n",
        "\n",
        "*   **Frontend**: React (Vite) with a \"Glassmorphism\" UI design, providing a seamless user experience.\n",
        "*   **Backend**: FastAPI (Python) for high-performance asynchronous request handling.\n",
        "*   **Database**: SQLite (SQLAlchemy) for relational data storage, using secure \"Vault\" columns for biometric templates.\n",
        "*   **AI/ML Core**:\n",
        "    *   **dlib/ResNet**: For face feature extraction.\n",
        "    *   **MobileNetV2 (Siamese)**: For fingerprint and palm texture analysis.\n",
        "*   **Security Layer**:\n",
        "    *   **BioHashing**: Cancelable biometrics for faces.\n",
        "    *   **IoM Hashing**: Index-of-Max hashing for fingerprints/palms.\n",
        "\n",
        "### 3. Key Algorithms & Models\n",
        "\n",
        "#### A. Face Recognition (ResNet-34)\n",
        "We utilize a pre-trained **ResNet-34** model (provided by dlib) mapped to a 128-dimensional hypersphere. This model is robust to lighting and pose variations.\n",
        "*   **Input**: Face Image\n",
        "*   **Output**: 128D Float Vector\n",
        "\n",
        "#### B. Cancelable Biometrics (BioHashing)\n",
        "To protect user privacy, raw face embeddings are never stored. Instead, we use **BioHashing**:\n",
        "1.  Generate a user-specific random **Token** (Seed).\n",
        "2.  Generate a random **Projection Matrix** from this seed.\n",
        "3.  Project the 128D feature vector into a new orthogonal space.\n",
        "4.  Detailed quantization (Thresholding) produces a binary string.\n",
        "*   **Benefit**: If a database is compromised, we just issue a new Token (revocability), unlike raw biometrics which cannot be changed.\n",
        "\n",
        "#### C. Siamese Networks & Triplet Loss\n",
        "For Fingerprint and Palm recognition, we fine-tuned a **Siamese Neural Network (MobileNetV2)** using **Triplet Loss**.\n",
        "*   **Goal**: Ensure embeddings of the same finger are closer (Euclidean distance) than embeddings of different fingers.\n",
        "*   **Triplet Loss**: `L = max(d(A,P) - d(A,N) + margin, 0)`\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 4. Implementation: Face Recognition Module\n",
        "\n",
        "In this section, we will walk through the implementation of the Face Recognition pipeline, exactly as it is used in the backend.\n",
        "\n",
        "**Steps:**\n",
        "1.  **Face Detection**: Locating the face in the image using HOG (Histogram of Oriented Gradients).\n",
        "2.  **Landmark Estimation**: Finding 68 key points (eyes, nose, jaw) to align the face.\n",
        "3.  **Feature Extraction**: Running the aligned face through ResNet to get the 128D embedding.\n",
        "4.  **BioHashing**: Securing the embedding.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Step 1: Import Dependencies\n",
        "import sys\n",
        "import os\n",
        "import cv2\n",
        "import dlib\n",
        "import numpy as np\n",
        "import secrets\n",
        "\n",
        "# Ensure backend paths are accessible\n",
        "sys.path.append(os.getcwd())\n",
        "\n",
        "print(\"[*] Libraries imported successfully.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "#### Step 2: Initialize Biometric Models\n",
        "We load the dlib pre-trained models:\n",
        "*   `shape_predictor_68_face_landmarks.dat`: For geometric alignment.\n",
        "*   `dlib_face_recognition_resnet_model_v1.dat`: The deep learning model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class BiometricDemo:\n",
        "    def __init__(self):\n",
        "        # Paths to models (adjust if necessary)\n",
        "        self.shape_path = \"shape_predictor_68_face_landmarks.dat\"\n",
        "        self.rec_path = \"dlib_face_recognition_resnet_model_v1.dat\"\n",
        "        \n",
        "        print(f\"[*] Loading Shape Predictor: {self.shape_path}...\")\n",
        "        self.detector = dlib.get_frontal_face_detector()\n",
        "        self.predictor = dlib.shape_predictor(self.shape_path)\n",
        "        \n",
        "        print(f\"[*] Loading ResNet Model: {self.rec_path}...\")\n",
        "        self.face_rec = dlib.face_recognition_model_v1(self.rec_path)\n",
        "        print(\"[+] Models Loaded.\")\n",
        "\n",
        "    def load_image(self, path):\n",
        "        # Load using OpenCV and convert to RGB (dlib expects RGB)\n",
        "        img = cv2.imread(path)\n",
        "        if img is None:\n",
        "            raise ValueError(f\"Could not load image: {path}\")\n",
        "        return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "bs_demo = BiometricDemo()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "#### Step 3: Feature Extraction Pipeline\n",
        "The `extract_features` function performs the core logic:\n",
        "1.  **Detect** faces in the image.\n",
        "2.  **Align** the face using the 68 landmarks.\n",
        "3.  **Compute** the 128D descriptor.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def extract_features(model, image):\n",
        "    # 1. Detect Features\n",
        "    dets = model.detector(image, 1)\n",
        "    if len(dets) == 0:\n",
        "        print(\"[-] No face detected.\")\n",
        "        return None\n",
        "    \n",
        "    print(f\"[+] Detected {len(dets)} face(s). Processing the first one.\")\n",
        "    \n",
        "    # 2. Get Landmarks & Align\n",
        "    shape = model.predictor(image, dets[0])\n",
        "    \n",
        "    # 3. Compute Descriptor (ResNet)\n",
        "    face_descriptor = model.face_rec.compute_face_descriptor(image, shape)\n",
        "    \n",
        "    # Convert dlib vector to numpy array\n",
        "    return np.array(face_descriptor)\n",
        "\n",
        "# Example Usage (Placeholder for demo)\n",
        "# image = bs_demo.load_image(\"path/to/test.jpg\")\n",
        "# features = extract_features(bs_demo, image)\n",
        "# print(f\"Feature Vector Shape: {features.shape}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "#### Step 4: Security - BioHashing\n",
        "Now we implement the **Cancelable Biometric** transformation.\n",
        "We project the 128D vector onto a random orthogonal basis generated from a user-specific \"seed token\".\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def generate_biohash(feature_vector, token_seed, hash_length=128):\n",
        "    # Ensure reproducibility with the seed\n",
        "    np.random.seed(token_seed)\n",
        "    \n",
        "    feature_len = len(feature_vector)\n",
        "    \n",
        "    # Generate random Projection Matrix (Random Orthonormal-ish)\n",
        "    projection_matrix = np.random.randn(feature_len, hash_length)\n",
        "    \n",
        "    # Project: (1x128) dot (128x128) -> (1x128)\n",
        "    projected = np.dot(feature_vector, projection_matrix)\n",
        "    \n",
        "    # Thresholding (Binarization)\n",
        "    # If value > 0 -> 1, else 0\n",
        "    biohash = (projected > 0).astype(int)\n",
        "    \n",
        "    return biohash\n",
        "\n",
        "# Example:\n",
        "# seed = 12345\n",
        "# protected_template = generate_biohash(features, seed)\n",
        "# print(f\"BioHash: {protected_template}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 5. Conclusion\n",
        "This implementation ensures that:\n",
        "1.  **High Accuracy**: Leveraging ResNet-34.\n",
        "2.  **Privacy**: Storing only the randomized BioHash.\n",
        "3.  **Revocability**: If a hash is stolen, we simply rotate the `token_seed` and generate a new hash, effectively \"changing\" the user's biometric password.\n",
        "\n",
        "End of Report.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}